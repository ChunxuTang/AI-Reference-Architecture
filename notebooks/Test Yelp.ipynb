{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b285659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import transformers \n",
    "import torch.optim as optimize\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torchtext\n",
    "import torchdata\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb40bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/aowu/Downloads/yelp_test\"\n",
    "batch_size = 16\n",
    "#num_workers = 2\n",
    "num_epochs = 10\n",
    "profiler_enabled = True\n",
    "profiler_log_path = \"/Users/aowu/Downloads/yelp_test_log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2230c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99365db4",
   "metadata": {},
   "source": [
    "### Checking device used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82d5d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b2b167",
   "metadata": {},
   "source": [
    "### Build and Preprocess use torchdata.datapipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddebf3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapipe = torchdata.datapipes.iter.FileLister(file_path).filter(filter_fn=lambda filename: filename.endswith('.csv'))\n",
    "datapipe = torchdata.datapipes.iter.FileOpener(datapipe, mode = 'rt')\n",
    "datapipe = datapipe.parse_csv(delimiter = ',', skip_lines = 1)\n",
    "N_rows = 500\n",
    "\n",
    "# Drop irrelevant cols\n",
    "r_datapipe = datapipe.drop([0,1,2,4,5,6,8])\n",
    "\n",
    "# Classify Stars: 1,2 -> negative; 3,4,5 -> positive\n",
    "score,text = r_datapipe.unzip(sequence_length=2)\n",
    "def classify(x):\n",
    "    if int(x) >2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "map_score = score.map(classify)\n",
    "\n",
    "# Lower Reviews for BertTokenizer\n",
    "def uncase(x):\n",
    "    return x.lower()\n",
    "\n",
    "lower_text = text.map(uncase)\n",
    "clean_datapipe = lower_text.zip(map_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bae9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_datapipe = lower_text.zip(map_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7915f7",
   "metadata": {},
   "source": [
    "### Build Dataset and DataLoader using datapipes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c30434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "class yelpDataset(Dataset):\n",
    "    def __init__(self, tokenizer, dp, max_length):\n",
    "        super(yelpDataset, self).__init__()\n",
    "        self.dp = dp\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length=max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(list(self.dp))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        text = list(self.dp)[index][0]\n",
    "        #tokenize,pad and encode reviews\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            pad_to_max_length=True,\n",
    "            max_length=self.max_length,\n",
    "        )\n",
    "        \n",
    "        encoded_text = inputs[\"input_ids\"]\n",
    "\n",
    "        return {\n",
    "            \"encoded_text\": torch.tensor(encoded_text, dtype=torch.long),\n",
    "            \"label\": torch.tensor(list(self.dp)[index][1], dtype=torch.long)\n",
    "            }\n",
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "dataset= yelpDataset(tokenizer,clean_datapipe, max_length=128)\n",
    "\n",
    "# Split Dataset to train, valid and test\n",
    "train_ds, valid_ds,test_ds = random_split(dataset,[0.8,0.1,0.1])\n",
    "\n",
    "# Build DataLoader for train, valid and test Dataset\n",
    "train_dl = DataLoader(dataset = train_ds, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "valid_dl = DataLoader(dataset = valid_ds, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "test_dl = DataLoader(dataset = test_ds, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b563594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ds[0][\"encoded_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f69aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3246aaba",
   "metadata": {},
   "source": [
    "### Build model from pretrained BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2fe8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "        model_name = \"bert-base-uncased\"\n",
    "        self.encoder = transformers.BertForSequenceClassification.from_pretrained(model_name, num_labels = 2, return_dict = True)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None,\n",
    "            position_ids=None, head_mask=None, labels=None):\n",
    "        loss, logits = self.encoder(input_ids, labels=labels)[:2]\n",
    "        \n",
    "        return loss,logits\n",
    "\n",
    "# Save model\n",
    "def save_checkpoints(path, model, valid_loss):\n",
    "    \n",
    "    if path == None:\n",
    "        return\n",
    "    state_dict =  {\"model_state_dict\": model.state_dict(),\n",
    "                  \"valid_loss\": valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "    \n",
    "    \n",
    "# Load Model\n",
    "def load_checkpoints(path, model):\n",
    "    if path == None:\n",
    "        return\n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f\"Model loaded from {path}\")\n",
    "    \n",
    "    model.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "    return state_dict[\"valid_loss\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ef09b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BERT()\n",
    "# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "# labels = torch.tensor([1]).unsqueeze(0)\n",
    "# outputs = model(**inputs, labels=labels)\n",
    "# loss = outputs[0]\n",
    "# logits = outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3cdb172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b27d34",
   "metadata": {},
   "source": [
    "### Setup Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae58db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler = None\n",
    "if profiler_enabled:\n",
    "    profiler = torch.profiler.profile(\n",
    "        schedule=torch.profiler.schedule(\n",
    "            wait=1, warmup=1, active=1, repeat=1\n",
    "        ),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(\n",
    "            profiler_log_path\n",
    "        ),\n",
    "        profile_memory = True\n",
    "    )\n",
    "    profiler.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b8885f",
   "metadata": {},
   "source": [
    "### Fine Tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fb9fad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BERT()\n",
    "model = model.to(device)\n",
    "optimizer = optimize.Adam(model.parameters(), lr = 1e-6, weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b339c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epoch = num_epochs,train_dl=train_dl,valid_dl=valid_dl, model=model, optimizer=optimizer, criterion = nn.BCELoss(), file_path=file_path):\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    print(f\"Started training at the timestamp{start_time}\")\n",
    "          \n",
    "    # Set up metrics\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    total_train_loss = []\n",
    "    total_valid_loss = []\n",
    "    lowest_loss = float(\"Inf\")\n",
    "    \n",
    "    #training model loop\n",
    "    model.train()\n",
    "    for  epoch in range(num_epoch):\n",
    "        print(\"epoch:\"+ str(epoch))\n",
    "        \n",
    "        for item in tqdm(train_dl, leave = True):\n",
    "            text = item[\"encoded_text\"]\n",
    "            text = text.to(device)\n",
    "            label = item[\"label\"]\n",
    "            label = label.unsqueeze(1)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            output = model(text,labels = label)\n",
    "            loss = output[0]\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update train loss\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Evaluate\n",
    "        model.eval()\n",
    "        with torch.no_grad():                    \n",
    "\n",
    "            # validation loop\n",
    "\n",
    "            for item in valid_dl:\n",
    "                text = item[\"encoded_text\"]\n",
    "                text = text.to(device)\n",
    "                label = item[\"label\"]\n",
    "                label = label.unsqueeze(1)\n",
    "                label = label.to(device)\n",
    "                output = model(text,labels = label)\n",
    "                loss = output[0]\n",
    "\n",
    "                valid_loss += loss.item()\n",
    "                \n",
    "        avg_train_loss = train_loss / len(train_dl)\n",
    "        avg_valid_loss = valid_loss / len(valid_dl)\n",
    "        total_train_loss.append(avg_train_loss)\n",
    "        total_valid_loss.append(avg_valid_loss)\n",
    "\n",
    "        # Monitor training progress\n",
    "        print(\"Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}\"\n",
    "              .format(epoch+1, num_epoch,\n",
    "                      avg_train_loss, avg_valid_loss))\n",
    "\n",
    "        # Save model if valid loss gets lower\n",
    "        if lowest_loss > valid_loss:\n",
    "            lowest_loss = valid_loss\n",
    "            save_checkpoints(file_path + '/' + 'model.pt', model, lowest_loss)\n",
    "\n",
    "        # Reset Metrics\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        if profiler_enabled:\n",
    "            profiler.step()\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "   \n",
    "    print(f\"Started training at the timestamp{end_time}\")\n",
    "    print(f\"Training time in {end_time - start_time:0.4f} seconds\")\n",
    "    \n",
    "    if profiler_enabled:\n",
    "        profiler.stop()\n",
    "        print(\"The profiler is completed. Please open the TensorBoard to browse the metrics.\")\n",
    "    \n",
    "    return total_train_loss, total_valid_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "788bee9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training at the timestamp173.718095291\n",
      "epoch:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████| 25/25 [00:46<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.6265, Valid Loss: 0.5374\n",
      "Model saved to /Users/aowu/Downloads/yelp_test/model.pt\n",
      "epoch:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:52<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.5267, Valid Loss: 0.5724\n",
      "epoch:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:30<00:00,  3.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.4810, Valid Loss: 0.5442\n",
      "epoch:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:52<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.4545, Valid Loss: 0.3953\n",
      "Model saved to /Users/aowu/Downloads/yelp_test/model.pt\n",
      "epoch:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.4376, Valid Loss: 0.5590\n",
      "epoch:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.4279, Valid Loss: 0.3714\n",
      "Model saved to /Users/aowu/Downloads/yelp_test/model.pt\n",
      "epoch:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.4179, Valid Loss: 0.3691\n",
      "Model saved to /Users/aowu/Downloads/yelp_test/model.pt\n",
      "epoch:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.4110, Valid Loss: 0.3537\n",
      "Model saved to /Users/aowu/Downloads/yelp_test/model.pt\n",
      "epoch:8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.4046, Valid Loss: 0.6076\n",
      "epoch:9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 0.3984, Valid Loss: 0.3346\n",
      "Model saved to /Users/aowu/Downloads/yelp_test/model.pt\n",
      "Started training at the timestamp1063.468643958\n",
      "Training time in 889.7505 seconds\n",
      "The profiler is completed. Please open the TensorBoard to browse the metrics.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.6265216660499573,\n",
       "  0.5266794669628143,\n",
       "  0.48095343708992006,\n",
       "  0.4544847583770752,\n",
       "  0.4376257574558258,\n",
       "  0.42785451412200926,\n",
       "  0.41793574929237365,\n",
       "  0.4110111713409424,\n",
       "  0.40463495552539824,\n",
       "  0.3984425389766693],\n",
       " [0.5373750329017639,\n",
       "  0.5723609253764153,\n",
       "  0.5441929996013641,\n",
       "  0.3952593356370926,\n",
       "  0.5590322911739349,\n",
       "  0.37139831483364105,\n",
       "  0.36912816762924194,\n",
       "  0.35369179397821426,\n",
       "  0.6075593680143356,\n",
       "  0.3346228748559952])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(num_epoch = num_epochs, train_dl = train_dl, valid_dl = valid_dl, \n",
    "      model = model, optimizer = optimizer, criterion = nn.BCELoss(), file_path = file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e722bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d96103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
